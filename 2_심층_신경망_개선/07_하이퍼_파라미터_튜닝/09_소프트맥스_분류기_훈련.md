---
title: 소프트맥스 분류기 훈련
---
$$
\begin{bmatrix}1\\0\\0\\0\end{bmatrix}\\
\text{Hard Max}
$$

$$
\begin{bmatrix}0.842\\0.042\\0.002\\0.114\end{bmatrix}\\
\text{Soft Max}
$$

- Hard Max 는 boolean 매트릭스로 회귀의 결과를 “Hard” 하게 표현된다.
- Soft Max 는 그에 반해 모든 클래스에 확률을 부여한다.
- 소프트맥스에서 $C=2$ 라면 로지스틱 회귀와 같다.

$$
y=\begin{bmatrix}0\\1\\0\\0\end{bmatrix}\\

$$

$$
a^{[L]}=\hat{y}=\begin{bmatrix}0.3\\0.2\\0.1\\0.4\end{bmatrix}\\
$$

$$
\mathcal{L}(y, \hat{y})=-\sum_{j=1}^Cy_j\log{\hat{y}_j}
$$

- 손실 함수는 위와같이 정의한다.
- 여기서 $y_2$ 만 $1$ 이므로, summation 의 결과는 $-\log{\hat{y}_2}=0.6989700043$ 가 된다.
- 모든 훈련 예제로 벡터화 한 $Y$ 의 차원은 $(C, m)$ 이 된다.

### 소프트맥스 미분

$$
dz^{[L]}=\hat{y}-y
$$