---
title: 미니 배치 그라데이션 하강
---
- NN은 실행과 평가가 매우 많이 반복되면서 학습됨
- 그렇기에 학습을 빠르게 진행하는 것이 중요함
- 학습 세트가 커지면 커질수록 속도는 매우 느려짐

### 미니 배치

- 훈련 세트의 데이터가 500만개 있다고 가정하면, 경사 하강을 한번 수행할 때 500만개의 데이터셋으로 산출한 비용 함수를 평가하고 역전파를 수행해야함
- 500만개를 n등분 해서 $\frac{5,000,000}{n}$ 만큼만 경사 하강을 수행하면 데이터셋을 모두 순회했을 때 $n$ 번 경사 하강을 수행할 수 있게 됨
- 이렇게 $m$ 개의 훈련세트를 나눠서 경사하강을 여러번 수행하도록 하는걸 mini batch 라고 함

- 새 표기법: $t$ 번째 mini match 를 $X^{\{t\}}$ 로 표현함
- 예) $m$ 이 5000개, $n$ 이 5 일때
    - $X^{\{1\}}=[x^{(1)},\dots,x^{(1000)}]$
    - $X^{\{2\}}=[x^{(1001)},\dots,x^{(2000)}]$
    - $X^{\{3\}}=[x^{(2001)},\dots,x^{(3000)}]$
    - $X^{\{4\}}=[x^{(3001)},\dots,x^{(4000)}]$
    - $X^{\{5\}}=[x^{(4001)},\dots,x^{(5000)}]$

- $m$ 개 훈련 예제를 $n$ 개의 미니 배치로 나누었을 때 비용함수는 다음과 같다.

$$
J^{\{t\}}=\frac{n}{m}\sum_{i=(t-1)\frac{m}{n}+1}^{t\frac{m}{n}}L(\hat{y}^{(i)}, y^{(i)})+\frac{\lambda}{2\frac{m}{n}}\sum_l||w^{[l]}||^2_F
$$

- 훈련 세트 $m$ 개를 모두 돌았을 때를 “1 epoch” 라고 표현한다.
- 즉 $n$개의 미니 배치가 있을 때 $n$번 경사 하강을 수행해야 “1 epoch”