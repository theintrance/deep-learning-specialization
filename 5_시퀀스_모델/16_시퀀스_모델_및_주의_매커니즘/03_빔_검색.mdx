---
title: 빔 검색
---

### 번역 모델에서 빔 서치 사용하기

* 번역 모델에서 빔 서치를 사용하여 가장 가능성이 높은 문장을 선택할 수 있다.

$$
V=\begin{bmatrix}
\text{a}\\
\vdots\\
\text{in}\\
\vdots\\
\text{jane}\\
\vdots\\
\text{september}\\
\vdots\\
\text{zulu}\\
\end{bmatrix}
$$

$$ V_n=10000 $$

![](/assets/5c3fc4f8-f9ae-453b-a8f4-099a3e58e836.png)

1. 먼저, 10,000개의 어휘 집합에서 첫 번째 단어를 선택해야 한다.
2. 빔 서치에서는 $B$ 라는 상수를 사용하여, 상위 $B$ 개의 후보만 남긴다. 여기서는 $B=3$ 으로 가정한다.
3. $P(y^{<1>}|x)$ 를 추정하여, 확률이 높은 상위 3개의 단어를 선택한다. 예를 들어 "in", "jane", "september" 가 선택되었다고 가정하자.
4. 이제 각각의 첫 번째 단어를 기준으로 두 번째 단어 $y^{<2>}$ 를 추정한다.
    * "in" 을 첫 번째 단어로 사용하면 $P(y^{<1>}=\text{"in"}, y^{<2>} | x)$ 를 추정한다.
    * 이는 $P(y^{<1>} | x)P(y^{<2>} | x, y^{<1>}=\text{"in"})$ 와 같이 계산된다.
5. 동일한 과정을 "jane", "september" 에 대해서도 적용한다. 이 단계에서 총 3개의 첫 번째 단어 각각에 대해 10,000개의 후보 쌍이 생성된다.
    * 즉, "in", "jane", "september" 각각에 대해 10,000개의 후보 쌍이 만들어진다.
6. 이제 30,000개의 후보 쌍 중에서 상위 $B=3$ 개의 후보 쌍만 선택한다. 예를 들어, 아래와 같은 후보들이 선택되었다고 가정하자.
    * "in september"
    * "jane is"
    * "jane visits"
7. 이 과정에서 처음에 선택되었던 "september" 는 첫 번째 단어로는 적합하지 않다는 것이 판명되었다.
8. 이제 남은 후보들로부터 세 번째 단어 $y^{<3>}$ 를 추정한다:
    * $P(y^{<3>} | x, \text{"in september"})$
    * $P(y^{<3>} | x, \text{"jane is"})$
    * $P(y^{<3>} | x, \text{"jane visits"})$
9. 이 과정을 끝 단어 (EOS 토큰) 가 나올 때까지 반복한다.

* 즉 빔 서치를 사용하면 $B$ 만큼의 경로가 동시에 유지되며, 각 스텝에서 상위 $B$ 개의 가능성 있는 경로를 남긴다.
