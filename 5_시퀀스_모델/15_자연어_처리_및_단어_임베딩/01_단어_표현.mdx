### 단어 표현

* 단어 시퀀스에서 해당 단어를 표현하기 위해 Vocabulary에서 해당 단어의 인덱스만 1인 one-hot 벡터를 사용했음.

$$
x^{<t>}=\begin{bmatrix}0\\0\\...\\1\\...\\0\end{bmatrix}\begin{matrix}\\\\\\\leftarrow1900,\text{ BAYERN}\\\\\\\end{matrix}
$$

* 위 경우 단어 "BAYERN"은 1900번째 단어이고, 앞으로 이 one-hot 벡터를 $O_{1900}$로 표기함.
* 그러나 이러한 벡터는 단어 간의 유사성을 반영할 수 없음. 예를 들어, "Apple"인 $O_{123}$과 "Orange"인 $O_{2313}$이 서로 유사하다는 것을 전혀 표현할 수 없으며, 두 벡터의 점곱이 항상 0임.

### Word Embeddings

* 단어 간 의미적 유사성을 반영하기 위해 Word Embedding을 사용함.
* 각 단어는 여러 의미를 표현하는 가중치 벡터로 변환되며, 예를 들어 아래와 같이 특정 의미들에 대한 가중치를 매길 수 있음.

|meaning|Man|Woman|King|Queen|Apple|Orange|
|---|---|---|---|---|---|---|
|Gender|-0.95|0.98|-0.97|0.99|0.02|0.03|
|Royal|0.01|0.02|0.97|0.98|0.01|0.02|
|Food|0.03|0.02|0.01|0.02|0.97|0.98|

* 총 300차원의 벡터로 각 단어를 표현할 수 있으며, 이 벡터를 Word Embedding이라고 함.
* 예를 들어 단어 "BAYERN"의 임베딩 벡터는 다음과 같음:

$$
\text{(BAYERN)}\\e_{1900}=\begin{bmatrix}-0.95\\0.01\\\vdots\\0.03\end{bmatrix}
$$

$$
n_{e_{1900}}=300
$$

* 이처럼 Word Embedding을 사용하면 "Apple"과 "Orange"가 의미적으로 유사하다는 것을 벡터의 값으로 표현할 수 있음. 이러한 벡터는 유사한 의미를 가진 단어일수록 가까운 벡터 공간에 위치하게 됨.

### t-SNE

* 고차원의 단어 벡터를 저차원으로 시각화하는 기법으로 t-SNE를 사용할 수 있음.
* t-SNE는 고차원의 데이터를 2차원 또는 3차원의 공간으로 변환하여 시각화함.
* 이를 통해 단어 간 의미적 유사성을 저차원 공간에서 시각적으로 표현할 수 있으며, 유사한 의미를 가진 단어들이 그룹을 이루는 경향을 볼 수 있음.