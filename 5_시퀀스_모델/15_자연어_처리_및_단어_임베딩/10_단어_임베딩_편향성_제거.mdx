---
title: 단어 임베딩 편향성 제거
---

### 워드 임베딩 모델의 편향

* 우리는 앞선 강의들로 Man:Woman 의 관계를 통해 King: 에서 Queen 을 예측할 수 있었다.
* 그렇다면 Man:Computer_Programmer 에서 Woman: 은 어떻게 예측될까?

* 모델은 간혹 해당 경우에 Woman:Homemaker 를 예측할 수 있다.
    * 이것은 잘못된 것이고 해로운 고정관념을 강요한다.

* 즉 워드 임베딩에서는 성별, 민족, 나이, 종교, 성격 등의 바이어스를 반영하여 예측할 수 있다.

### 편향 제거

* babysitter, doctor, grandmother, grandfather, girl, she, he, boy 등의 임베딩 벡터를 2D 공간 위에 표현해보자.
* 이 단어들에서 어떤 평향을 줄일건지 먼저 정한다. 이 경우 성별 편향을 줄여보자

1. 성별이 다른 두 단어의 쌍을 여러개 고르고 쌍끼리의 차의 평균을 구한다.

$$
((e_{girl} - e_{boy}) + (e_{grandmother} - e_{grandfather}) + (e_{she} - e_{he}) \dots) / N
$$

2. 이렇게 했을 때 2D 공간에서 어느 축이 성별 편향을 나타내는지 확인할 수 있다.
3. 해당 축을 bias direction 이라고 하고 편향에 영향을 끼치지 않는 축을 non-bias direction 이라고 한다.
4. **중립화**: 성적으로 중립적이야 하는 단어들 (doctor, babysitter, nurse 등) 의 임베딩 벡터들을 bias direction이 0 이되는 쪽으로 이동시킨다. 
    * 즉 벡터에서 bias direction 축 성분을 제거한다.

![](/assets/e7d5d759-14a5-4491-b130-54440b6d1e4f.png)

5. **평준화**: 중립 단어들을 이동시켰고, 이제 서로 성별만 다른 단어들 (girl:boy, grandmother:grandfather) 의 임베딩 벡터들의 위치도 non-bias direction 축과의 거리가 같도록 조정한다.
    * 즉 $d(e_{girl}, e_{babysitter}) = d(e_{boy}, e_{babysitter})$ 가 되도록 한다.

![](/assets/93902547-11e1-4cbc-aad6-24d238d66e4b.png)

* 이와 같은 방법으로 편향을 줄일 수는 있지만, 중립화와 평쥰화 될 벡터는 누가 어떻게 선정하는가?
     * 예: beard (수염) 같은 경우 남자쪽으로 벡터가 치우쳐야할까?
* 이 알고리즘은 설명한 것 보다 더 복잡하기 때문에 논문을 참고하자.
    * [Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings](https://arxiv.org/pdf/1607.06520)