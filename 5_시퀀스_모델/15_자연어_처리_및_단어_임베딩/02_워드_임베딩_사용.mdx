---
title: 워드 임베딩 사용
---

> Sally Johnson is an orange farmer.

* 워드 임베딩을 도입한 모델이 위 문장에서 "Sally Johnson"이 사람 이름이고, "orange farmer"라는 직업 표현을 잘 이해한다면, 아래 문장도 잘 처리할 수 있을 것이다.

> Robert Lin is an apple farmer.

* 워드 임베딩을 통해 "orange farmer"와 "apple farmer"가 의미적으로 비슷한 표현이라는 것을 학습했기 때문에, 두 문장에서 비슷한 직업을 표현하는 단어들을 쉽게 연결할 수 있다.

> Robert Lin is a durian cultivator.

* 하지만 이 문장에서는 "durian"과 "cultivator" 같은 단어들이 훈련 과정에서 등장하지 않았을 가능성이 높다. 이 경우 모델은 해당 단어들에 대한 임베딩을 학습하지 못했기 때문에 문장을 제대로 이해하지 못할 수 있다.

* 이러한 문제를 해결하기 위해, 레이블이 없는 방대한 단어 데이터셋을 사용해 워드 임베딩을 비지도 학습(Unsupervised Learning)으로 학습하면 모델 성능을 향상시킬 수 있다. 이는 모델이 훈련되지 않은 새로운 단어에 대해서도 더 잘 대응할 수 있게 도와준다.

### 얼굴 인식 모델과의 유사성

* 얼굴 인식 모델에서 얼굴 사진을 128개의 feature로 인코딩하여 벡터로 표현하고, 두 얼굴 간의 유사도를 벡터 간 거리로 판단하는 방식은 워드 임베딩 모델에서 단어 간 유사도를 계산하는 방법과 유사하다.
* 워드 임베딩에서도 단어를 벡터로 변환하고, 이 벡터들 간의 유사성을 벡터 간의 거리나 방향을 비교하여 판단한다.