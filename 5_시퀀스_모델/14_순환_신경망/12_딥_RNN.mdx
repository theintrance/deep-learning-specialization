### 더 깊은 레이어의 RNN (Deep RNN)

* 기존 RNN에서는 한 개의 레이어로 한 번의 연산만 거쳐 출력을 만들었다.

$$
\hat{y}^{<t>} = g(W_y[a^{<t-1>}, x^{<t>}] + b_y)
$$

  * 여기서 $a^{<t-1>}$는 이전 시점의 hidden state이고, $x^{<t>}$는 현재 시점의 입력값이다.

* 딥 RNN에서는 여러 층의 RNN이 쌓여 더 복잡한 패턴을 학습할 수 있도록 한다. 각 레이어는 이전 레이어의 출력값을 입력으로 받아들여, 여러 번의 연산을 거친 후 최종 출력을 만든다.

$$
a^{[l]<t>} = g(W_a^{[l]}[a^{[l]<t-1>}, a^{[l-1]<t>}] + b_a^{[l]})
$$

  * 여기서 $a^{[l]<t>}$는 $l$번째 레이어의 $t$ 시점에서의 hidden state를 나타내며, $a^{[l-1]<t>}$는 이전 레이어의 출력을 의미한다.

![](/assets/8cd1b204-2c29-4fb5-8d12-a85b24814723.png)

* 이 구조를 통해 딥 RNN은 한 번의 연산이 아닌, 여러 층을 통해 더욱 복잡한 패턴을 학습한다.
* 레이어의 마지막 출력값 $a^{[L]<t>}$를 바로 $\hat{y}^{<t>}$로 변환해 출력할 수 있지만, 더 많은 레이어를 쌓으면 더 복잡하고 추상적인 패턴을 학습할 수 있다.