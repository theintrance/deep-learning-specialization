---
title: 소셜 시퀀스 샘플링
---

![](/assets/aa92477e-d2c4-4470-8b97-13e986d57a5c.png)

### RNN의 시퀀스 예측 및 문자 단위 RNN

- **RNN의 예측 과정**:
    - RNN은 시간이 지남에 따라 이전에 예측한 단어들이 다음 단어의 예측에 영향을 미친다.
    - 각 시간 단계에서 **이전 단어의 예측값과 은닉 상태**를 활용하여 다음 단어를 예측하는 순환적 특성을 갖는다.
    - 이를 통해 RNN은 문맥을 기억하고, 문장의 일관성을 유지하며 시퀀스를 생성한다.
- **문자 단위 RNN**:
    - RNN은 단어 단위뿐만 아니라 **문자 단위**로도 학습할 수 있다.
    - 문자 단위 RNN에서 Vocabulary는 다음과 같이 정의할 수 있다:
        - Vocabulary=[a, b, c, d, ..., z, 0, ..., 9, " "]
    - 문자 단위 RNN은 **알 수 없는 단어(<unk> 토큰)**에 대해 걱정할 필요가 없다. 각 문자를 개별적으로 처리하기 때문에 모든 입력을 처리할 수 있다.
- **문자 단위 RNN vs 단어 단위 RNN**:
    - **문자 단위 RNN**:
        - 모든 문자를 개별 토큰으로 처리하여 **사전 밖 단어**에 대한 문제가 발생하지 않는다.
        - 그러나 **긴 시퀀스**를 처리해야 하므로, **더 많은 계산 리소스**와 학습 시간이 필요하다.
        - 문맥을 파악하기 위해 더 많은 시간 단계가 필요하며, 문자 수준의 패턴을 학습하는 것이 더 어렵다.
    - **단어 단위 RNN**:
        - 단어를 하나의 토큰으로 처리하므로, **더 적은 시간 단계**로 예측을 수행할 수 있어 **학습 속도**가 빠르다.
        - 하지만 사전에 없는 단어는 <unk>로 처리되므로, 새로운 단어에 대한 정보 손실이 발생할 수 있다.
- **핵심 요약**:
    - RNN은 예측된 단어들이 다음 예측에 영향을 미치는 순환적 구조를 통해 문맥을 유지하며, 시퀀스 예측을 수행한다.
    - 문자 단위 RNN은 단어 단위 RNN에 비해 더 많은 계산 자원이 필요하지만, 사전 밖 단어에 대한 문제가 없다.